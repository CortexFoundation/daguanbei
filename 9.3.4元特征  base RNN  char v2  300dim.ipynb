{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "window.load_remote_theme = true\n",
       "var theme_js = \"https://odhk.github.io/hyrule_theme/custom.js\";\n",
       "\n",
       "window.load_local_theme = function(){\n",
       "    var hostname = document.location.hostname\n",
       "    return ((hostname == \"localhost\" || hostname == '127.0.0.1') && !load_remote_theme)\n",
       "}\n",
       "\n",
       "var url = load_local_theme() ? document.location.origin + \"/files/theme/custom.js\" : theme_js\n",
       "\n",
       "$.getScript(url)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "window.load_remote_theme = true\n",
    "var theme_js = \"https://odhk.github.io/hyrule_theme/custom.js\";\n",
    "\n",
    "window.load_local_theme = function(){\n",
    "    var hostname = document.location.hostname\n",
    "    return ((hostname == \"localhost\" || hostname == '127.0.0.1') && !load_remote_theme)\n",
    "}\n",
    "\n",
    "var url = load_local_theme() ? document.location.origin + \"/files/theme/custom.js\" : theme_js\n",
    "\n",
    "$.getScript(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/libo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "1271461it [02:14, 9487.33it/s]\n",
      "  2%|▏         | 23846/1271460 [00:00<00:05, 238391.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1271460 unique tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1271460/1271460 [00:05<00:00, 236701.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import keras\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Lambda, Embedding,constraints,\\\n",
    "Dropout, Activation,GRU,Bidirectional,Subtract, Permute, TimeDistributed, Reshape\n",
    "from keras.layers import Conv1D,Conv2D,MaxPooling2D,GlobalAveragePooling1D,GlobalMaxPooling1D, MaxPooling1D, Flatten\n",
    "from keras.layers import CuDNNGRU, CuDNNLSTM, SpatialDropout1D,Layer, initializers, regularizers\n",
    "from keras.layers.merge import concatenate, Concatenate, Average, Dot, Maximum, Multiply, Subtract\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, LatentDirichletAllocation\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from keras.activations import softmax\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import *\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from scipy.special import erfinv\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train = pd.read_csv('train_set.csv')\n",
    "test = pd.read_csv('test_set.csv')\n",
    "\n",
    "label = train['class']\n",
    "\n",
    "char_embedding_index = {}\n",
    "f = open('word_embedding_300dim_new2.txt')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0].lower()\n",
    "    embeddings = np.asarray(values[1:], dtype = 'float32')\n",
    "    char_embedding_index[word] = embeddings\n",
    "f.close()\n",
    "\n",
    "len(char_embedding_index)\n",
    "\n",
    "api_embedding_file_path = 'word_embedding_300dim_new2.txt'\n",
    "embedding_dim = 300\n",
    "max_nb_api = len(char_embedding_index) + 1\n",
    "max_sequence_length_api =1000\n",
    "\n",
    "all_word = list(train['word_seg'].values) + list(test['word_seg'].values)\n",
    "\n",
    "all_word_list = []\n",
    "for i in list(all_word):\n",
    "    all_word_list.append(i.split(' '))\n",
    "\n",
    "len(all_word_list)\n",
    "\n",
    "train['word_seg'].apply(lambda x:len(x.split(' '))).describe()\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "tokenizer_api = Tokenizer()\n",
    "\n",
    "tokenizer_api.fit_on_texts(all_word_list)\n",
    "\n",
    "api_seq = tokenizer_api.texts_to_sequences(all_word_list)\n",
    "\n",
    "data['word_seq'] = pad_sequences(api_seq, maxlen = max_sequence_length_api, padding='post').tolist()\n",
    "\n",
    "api_index = tokenizer_api.word_index\n",
    "print('Found %s unique tokens' % len(api_index))\n",
    "nb_words = min(max_nb_api, len(char_embedding_index)+1)\n",
    "api_embedding_matrix = np.zeros((nb_words, embedding_dim))\n",
    "\n",
    "for word, i in tqdm(api_index.items()):\n",
    "    embedding_vector = char_embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        api_embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        print('no char%s'%word)\n",
    "\n",
    "data['id'] = train['id']\n",
    "\n",
    "train_FE = data.iloc[:len(label),:]\n",
    "test_FE = data.iloc[len(label):,:]\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "def get_input(df):\n",
    "    \n",
    "    _input = [np.array(df.word_seq.values.tolist())]\n",
    "    \n",
    "    \n",
    "    return _input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN1():\n",
    "    \n",
    "    #Input layer\n",
    "    char_input = Input(shape=(max_sequence_length_api,), dtype='int32')\n",
    "    \n",
    "    api_embedding_layer = Embedding(nb_words,\n",
    "        embedding_dim,\n",
    "        weights=[api_embedding_matrix],\n",
    "        input_length=max_sequence_length_api,\n",
    "        trainable=False)\n",
    "    \n",
    "    #RNN\n",
    "    char_rnn_layer_1 = Bidirectional(CuDNNLSTM(150, \n",
    "                               return_sequences=True))\n",
    "    char_rnn_layer_2 = Bidirectional(CuDNNLSTM(150, \n",
    "                               return_sequences=True))\n",
    "    \n",
    "    char_embedding = api_embedding_layer(char_input)\n",
    "    #char_embedding = SpatialDropout1D(0.2)(char_embedding)\n",
    "    \n",
    "    #双层BiLSTM\n",
    "    char_rnn_1= char_rnn_layer_1(char_embedding)\n",
    "    char_rnn_2= char_rnn_layer_2(char_rnn_1)\n",
    "    \n",
    "    #max avg\n",
    "    char_att_maxpooling_1 = GlobalMaxPooling1D()(char_rnn_1)\n",
    "    char_att_avgpooling_1 = GlobalAveragePooling1D()(char_rnn_1)\n",
    "    \n",
    "    char_att_maxpooling_2 = GlobalMaxPooling1D()(char_rnn_2)\n",
    "    char_att_avgpooling_2 = GlobalAveragePooling1D()(char_rnn_2)\n",
    "    \n",
    "#     max_sub_char_abs = Lambda(lambda x:K.abs(x[0] - x[1]))([char_att_maxpooling_1, char_att_maxpooling_2])\n",
    "#     max_multi_char = Lambda(lambda x: x[0] * x[1])([char_att_maxpooling_1, char_att_maxpooling_2])\n",
    "\n",
    "#     avg_sub_char_abs = Lambda(lambda x:K.abs(x[0] - x[1]))([char_att_avgpooling_1, char_att_avgpooling_2])\n",
    "#     avg_multi_char = Lambda(lambda x: x[0] * x[1])([char_att_avgpooling_1, char_att_avgpooling_2])\n",
    "\n",
    "    merged = concatenate([char_att_maxpooling_1, char_att_avgpooling_1, \\\n",
    "                          char_att_maxpooling_2, char_att_avgpooling_2,])\n",
    "    merged = Dropout(0.2)(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dense(512, activation='relu')(merged)\n",
    "    merged = Dropout(0.1)(merged)\n",
    "    merged = BatchNormalization()(merged) \n",
    "    preds = Dense(19, activation = 'softmax')(merged)\n",
    "    \n",
    "    model = Model(inputs=[char_input],outputs=preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_train = pd.DataFrame(np.array([None]*train_FE.shape[0]*19).reshape(train_FE.shape[0], 19))\n",
    "meta_train.columns = ['prob' + str(x) for x in range(19)]\n",
    "meta_test = pd.DataFrame()\n",
    "\n",
    "label = train['class']\n",
    "\n",
    "label = label - 1\n",
    "\n",
    "categorical_labels = keras.utils.np_utils.to_categorical(label, num_classes=19)\n",
    "\n",
    "index = pd.read_csv('fold.csv')\n",
    "index['id'] = train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train, test, all_word\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******0*******\n",
      "Train on 92040 samples, validate on 10237 samples\n",
      "Epoch 1/20\n",
      "92040/92040 [==============================] - 367s 4ms/step - loss: 1.0371 - acc: 0.7013 - val_loss: 0.9383 - val_acc: 0.7168\n",
      "Epoch 2/20\n",
      "92040/92040 [==============================] - 366s 4ms/step - loss: 0.8349 - acc: 0.7521 - val_loss: 0.8795 - val_acc: 0.7418\n",
      "Epoch 3/20\n",
      "92040/92040 [==============================] - 366s 4ms/step - loss: 0.7706 - acc: 0.7693 - val_loss: 0.8129 - val_acc: 0.7536\n",
      "Epoch 4/20\n",
      "92040/92040 [==============================] - 367s 4ms/step - loss: 0.7201 - acc: 0.7830 - val_loss: 0.8658 - val_acc: 0.7466\n",
      "Epoch 5/20\n",
      "92040/92040 [==============================] - 366s 4ms/step - loss: 0.6677 - acc: 0.7967 - val_loss: 0.7720 - val_acc: 0.7672\n",
      "Epoch 6/20\n",
      "92040/92040 [==============================] - 366s 4ms/step - loss: 0.6208 - acc: 0.8089 - val_loss: 0.8255 - val_acc: 0.7658\n",
      "Epoch 7/20\n",
      "92040/92040 [==============================] - 368s 4ms/step - loss: 0.5699 - acc: 0.8218 - val_loss: 0.8053 - val_acc: 0.7687\n",
      "Epoch 8/20\n",
      "92040/92040 [==============================] - 366s 4ms/step - loss: 0.5207 - acc: 0.8331 - val_loss: 0.7853 - val_acc: 0.7729\n",
      "Epoch 9/20\n",
      "92040/92040 [==============================] - 366s 4ms/step - loss: 0.4731 - acc: 0.8478 - val_loss: 0.8124 - val_acc: 0.7765\n",
      "Epoch 10/20\n",
      "92040/92040 [==============================] - 368s 4ms/step - loss: 0.4277 - acc: 0.8617 - val_loss: 0.8131 - val_acc: 0.7816\n",
      "Epoch 11/20\n",
      "92040/92040 [==============================] - 363s 4ms/step - loss: 0.3835 - acc: 0.8744 - val_loss: 0.8675 - val_acc: 0.7748\n",
      "Epoch 12/20\n",
      "92040/92040 [==============================] - 363s 4ms/step - loss: 0.3428 - acc: 0.8849 - val_loss: 1.0033 - val_acc: 0.7688\n",
      "10237/10237 [==============================] - 16s 2ms/step\n",
      "102277/102277 [==============================] - 161s 2ms/step\n",
      "*******1*******\n",
      "Train on 92043 samples, validate on 10234 samples\n",
      "Epoch 1/20\n",
      "92043/92043 [==============================] - 367s 4ms/step - loss: 1.0352 - acc: 0.7000 - val_loss: 0.9370 - val_acc: 0.7313\n",
      "Epoch 2/20\n",
      "92043/92043 [==============================] - 366s 4ms/step - loss: 0.8306 - acc: 0.7540 - val_loss: 0.9541 - val_acc: 0.7246\n",
      "Epoch 3/20\n",
      "92043/92043 [==============================] - 368s 4ms/step - loss: 0.7620 - acc: 0.7710 - val_loss: 0.8229 - val_acc: 0.7549\n",
      "Epoch 4/20\n",
      "92043/92043 [==============================] - 366s 4ms/step - loss: 0.7118 - acc: 0.7852 - val_loss: 0.8770 - val_acc: 0.7402\n",
      "Epoch 5/20\n",
      "92043/92043 [==============================] - 368s 4ms/step - loss: 0.6622 - acc: 0.7985 - val_loss: 0.8239 - val_acc: 0.7607\n",
      "Epoch 6/20\n",
      "92043/92043 [==============================] - 366s 4ms/step - loss: 0.6164 - acc: 0.8104 - val_loss: 0.8218 - val_acc: 0.7671\n",
      "Epoch 7/20\n",
      "92043/92043 [==============================] - 366s 4ms/step - loss: 0.5671 - acc: 0.8228 - val_loss: 0.7949 - val_acc: 0.7697\n",
      "Epoch 8/20\n",
      "92043/92043 [==============================] - 368s 4ms/step - loss: 0.5157 - acc: 0.8364 - val_loss: 0.8280 - val_acc: 0.7737\n",
      "Epoch 9/20\n",
      "92043/92043 [==============================] - 367s 4ms/step - loss: 0.4689 - acc: 0.8491 - val_loss: 0.8390 - val_acc: 0.7693\n",
      "Epoch 10/20\n",
      "92043/92043 [==============================] - 367s 4ms/step - loss: 0.4228 - acc: 0.8623 - val_loss: 0.9221 - val_acc: 0.7635\n",
      "10234/10234 [==============================] - 16s 2ms/step \n",
      "102277/102277 [==============================] - 162s 2ms/step\n",
      "*******2*******\n",
      "Train on 92044 samples, validate on 10233 samples\n",
      "Epoch 1/20\n",
      "92044/92044 [==============================] - 367s 4ms/step - loss: 1.0400 - acc: 0.7009 - val_loss: 0.9042 - val_acc: 0.7346\n",
      "Epoch 2/20\n",
      "92044/92044 [==============================] - 368s 4ms/step - loss: 0.8365 - acc: 0.7526 - val_loss: 0.9165 - val_acc: 0.7208\n",
      "Epoch 3/20\n",
      "92044/92044 [==============================] - 367s 4ms/step - loss: 0.7717 - acc: 0.7688 - val_loss: 0.8165 - val_acc: 0.7546\n",
      "Epoch 4/20\n",
      "92044/92044 [==============================] - 366s 4ms/step - loss: 0.7190 - acc: 0.7832 - val_loss: 0.7886 - val_acc: 0.7652\n",
      "Epoch 5/20\n",
      "92044/92044 [==============================] - 368s 4ms/step - loss: 0.6716 - acc: 0.7951 - val_loss: 0.7436 - val_acc: 0.7810\n",
      "Epoch 6/20\n",
      "92044/92044 [==============================] - 367s 4ms/step - loss: 0.6255 - acc: 0.8072 - val_loss: 0.7530 - val_acc: 0.7795\n",
      "Epoch 7/20\n",
      "92044/92044 [==============================] - 367s 4ms/step - loss: 0.5759 - acc: 0.8201 - val_loss: 0.7450 - val_acc: 0.7786\n",
      "10233/10233 [==============================] - 16s 2ms/step\n",
      "102277/102277 [==============================] - 161s 2ms/step\n",
      "*******3*******\n",
      "Train on 92046 samples, validate on 10231 samples\n",
      "Epoch 1/20\n",
      "92046/92046 [==============================] - 368s 4ms/step - loss: 1.0378 - acc: 0.7005 - val_loss: 0.9133 - val_acc: 0.7338\n",
      "Epoch 2/20\n",
      "92046/92046 [==============================] - 367s 4ms/step - loss: 0.8336 - acc: 0.7527 - val_loss: 0.8460 - val_acc: 0.7451\n",
      "Epoch 3/20\n",
      "92046/92046 [==============================] - 366s 4ms/step - loss: 0.7731 - acc: 0.7688 - val_loss: 0.8700 - val_acc: 0.7454\n",
      "Epoch 4/20\n",
      "92046/92046 [==============================] - 368s 4ms/step - loss: 0.7156 - acc: 0.7836 - val_loss: 0.7976 - val_acc: 0.7680\n",
      "Epoch 5/20\n",
      "92046/92046 [==============================] - 367s 4ms/step - loss: 0.6679 - acc: 0.7960 - val_loss: 0.7802 - val_acc: 0.7675\n",
      "Epoch 6/20\n",
      "92046/92046 [==============================] - 365s 4ms/step - loss: 0.6182 - acc: 0.8081 - val_loss: 0.7561 - val_acc: 0.7794\n",
      "Epoch 7/20\n",
      "92046/92046 [==============================] - 367s 4ms/step - loss: 0.5717 - acc: 0.8208 - val_loss: 0.7930 - val_acc: 0.7808\n",
      "Epoch 8/20\n",
      "92046/92046 [==============================] - 366s 4ms/step - loss: 0.5262 - acc: 0.8337 - val_loss: 0.7568 - val_acc: 0.7796\n",
      "Epoch 9/20\n",
      "92046/92046 [==============================] - 364s 4ms/step - loss: 0.4785 - acc: 0.8477 - val_loss: 0.7982 - val_acc: 0.7761\n",
      "10231/10231 [==============================] - 16s 2ms/step\n",
      "102277/102277 [==============================] - 159s 2ms/step\n",
      "*******4*******\n",
      "Train on 92049 samples, validate on 10228 samples\n",
      "Epoch 1/20\n",
      "92049/92049 [==============================] - 366s 4ms/step - loss: 1.0380 - acc: 0.6998 - val_loss: 1.0036 - val_acc: 0.7038\n",
      "Epoch 2/20\n",
      "92049/92049 [==============================] - 366s 4ms/step - loss: 0.8321 - acc: 0.7533 - val_loss: 0.8620 - val_acc: 0.7453\n",
      "Epoch 3/20\n",
      "92049/92049 [==============================] - 366s 4ms/step - loss: 0.7693 - acc: 0.7698 - val_loss: 0.8039 - val_acc: 0.7628\n",
      "Epoch 4/20\n",
      "92049/92049 [==============================] - 365s 4ms/step - loss: 0.7170 - acc: 0.7821 - val_loss: 0.7864 - val_acc: 0.7657\n",
      "Epoch 5/20\n",
      "92049/92049 [==============================] - 365s 4ms/step - loss: 0.6685 - acc: 0.7959 - val_loss: 0.7954 - val_acc: 0.7620\n",
      "Epoch 6/20\n",
      "92049/92049 [==============================] - 367s 4ms/step - loss: 0.6170 - acc: 0.8089 - val_loss: 0.8386 - val_acc: 0.7550\n",
      "10228/10228 [==============================] - 16s 2ms/step\n",
      "102277/102277 [==============================] - 161s 2ms/step\n",
      "*******5*******\n",
      "Train on 92051 samples, validate on 10226 samples\n",
      "Epoch 1/20\n",
      "92051/92051 [==============================] - 367s 4ms/step - loss: 1.0397 - acc: 0.6996 - val_loss: 0.8964 - val_acc: 0.7390\n",
      "Epoch 2/20\n",
      "92051/92051 [==============================] - 366s 4ms/step - loss: 0.8318 - acc: 0.7539 - val_loss: 0.9508 - val_acc: 0.7207\n",
      "Epoch 3/20\n",
      "92051/92051 [==============================] - 367s 4ms/step - loss: 0.7652 - acc: 0.7717 - val_loss: 0.8002 - val_acc: 0.7638\n",
      "Epoch 4/20\n",
      "92051/92051 [==============================] - 367s 4ms/step - loss: 0.7165 - acc: 0.7837 - val_loss: 0.8312 - val_acc: 0.7578\n",
      "Epoch 5/20\n",
      "92051/92051 [==============================] - 367s 4ms/step - loss: 0.6656 - acc: 0.7965 - val_loss: 0.8346 - val_acc: 0.7484\n",
      "10226/10226 [==============================] - 16s 2ms/step\n",
      "102277/102277 [==============================] - 160s 2ms/step\n",
      "*******6*******\n",
      "Train on 92053 samples, validate on 10224 samples\n",
      "Epoch 1/20\n",
      "92053/92053 [==============================] - 365s 4ms/step - loss: 1.0481 - acc: 0.6973 - val_loss: 0.9567 - val_acc: 0.7217\n",
      "Epoch 2/20\n",
      "92053/92053 [==============================] - 366s 4ms/step - loss: 0.8369 - acc: 0.7508 - val_loss: 0.7946 - val_acc: 0.7632\n",
      "Epoch 3/20\n",
      "92053/92053 [==============================] - 365s 4ms/step - loss: 0.7707 - acc: 0.7687 - val_loss: 0.8002 - val_acc: 0.7692\n",
      "Epoch 4/20\n",
      "92053/92053 [==============================] - 366s 4ms/step - loss: 0.7192 - acc: 0.7818 - val_loss: 0.7979 - val_acc: 0.7698\n",
      "Epoch 5/20\n",
      "92053/92053 [==============================] - 367s 4ms/step - loss: 0.6731 - acc: 0.7946 - val_loss: 0.7461 - val_acc: 0.7831\n",
      "Epoch 6/20\n",
      "92053/92053 [==============================] - 359s 4ms/step - loss: 0.6225 - acc: 0.8072 - val_loss: 0.7451 - val_acc: 0.7858\n",
      "Epoch 7/20\n",
      "92053/92053 [==============================] - 365s 4ms/step - loss: 0.5746 - acc: 0.8207 - val_loss: 0.7353 - val_acc: 0.7906\n",
      "Epoch 8/20\n",
      "92053/92053 [==============================] - 365s 4ms/step - loss: 0.5244 - acc: 0.8347 - val_loss: 0.7484 - val_acc: 0.7835\n",
      "Epoch 9/20\n",
      "92053/92053 [==============================] - 368s 4ms/step - loss: 0.4746 - acc: 0.8477 - val_loss: 0.8036 - val_acc: 0.7856\n",
      "10224/10224 [==============================] - 17s 2ms/step\n",
      "102277/102277 [==============================] - 161s 2ms/step\n",
      "*******7*******\n",
      "Train on 92054 samples, validate on 10223 samples\n",
      "Epoch 1/20\n",
      "92054/92054 [==============================] - 368s 4ms/step - loss: 1.0367 - acc: 0.7020 - val_loss: 0.9586 - val_acc: 0.7214\n",
      "Epoch 2/20\n",
      "92054/92054 [==============================] - 365s 4ms/step - loss: 0.8320 - acc: 0.7539 - val_loss: 0.9627 - val_acc: 0.7255\n",
      "Epoch 3/20\n",
      "92054/92054 [==============================] - 364s 4ms/step - loss: 0.7647 - acc: 0.7714 - val_loss: 0.9486 - val_acc: 0.7161\n",
      "Epoch 4/20\n",
      "92054/92054 [==============================] - 367s 4ms/step - loss: 0.7131 - acc: 0.7843 - val_loss: 0.8069 - val_acc: 0.7662\n",
      "Epoch 5/20\n",
      "92054/92054 [==============================] - 366s 4ms/step - loss: 0.6660 - acc: 0.7966 - val_loss: 0.7668 - val_acc: 0.7743\n",
      "Epoch 6/20\n",
      "92054/92054 [==============================] - 367s 4ms/step - loss: 0.6160 - acc: 0.8102 - val_loss: 0.7753 - val_acc: 0.7746\n",
      "Epoch 7/20\n",
      "92054/92054 [==============================] - 367s 4ms/step - loss: 0.5684 - acc: 0.8219 - val_loss: 0.7734 - val_acc: 0.7792\n",
      "Epoch 8/20\n",
      "92054/92054 [==============================] - 366s 4ms/step - loss: 0.5166 - acc: 0.8358 - val_loss: 0.7917 - val_acc: 0.7746\n",
      "Epoch 9/20\n",
      "92054/92054 [==============================] - 368s 4ms/step - loss: 0.4671 - acc: 0.8490 - val_loss: 0.8396 - val_acc: 0.7740\n",
      "10223/10223 [==============================] - 16s 2ms/step\n",
      "102277/102277 [==============================] - 160s 2ms/step\n",
      "*******8*******\n",
      "Train on 92056 samples, validate on 10221 samples\n",
      "Epoch 1/20\n",
      "92056/92056 [==============================] - 367s 4ms/step - loss: 1.0431 - acc: 0.6977 - val_loss: 0.9053 - val_acc: 0.7349\n",
      "Epoch 2/20\n",
      "92056/92056 [==============================] - 366s 4ms/step - loss: 0.8376 - acc: 0.7532 - val_loss: 0.8460 - val_acc: 0.7481\n",
      "Epoch 3/20\n",
      "92056/92056 [==============================] - 365s 4ms/step - loss: 0.7736 - acc: 0.7696 - val_loss: 0.8173 - val_acc: 0.7545\n",
      "Epoch 4/20\n",
      "92056/92056 [==============================] - 367s 4ms/step - loss: 0.7195 - acc: 0.7839 - val_loss: 0.7421 - val_acc: 0.7808\n",
      "Epoch 5/20\n",
      "92056/92056 [==============================] - 366s 4ms/step - loss: 0.6712 - acc: 0.7946 - val_loss: 0.7798 - val_acc: 0.7707\n",
      "Epoch 6/20\n",
      "92056/92056 [==============================] - 365s 4ms/step - loss: 0.6219 - acc: 0.8083 - val_loss: 0.7315 - val_acc: 0.7816\n",
      "Epoch 7/20\n",
      "92056/92056 [==============================] - 360s 4ms/step - loss: 0.5714 - acc: 0.8205 - val_loss: 0.7485 - val_acc: 0.7839\n",
      "Epoch 8/20\n",
      "92056/92056 [==============================] - 367s 4ms/step - loss: 0.5220 - acc: 0.8354 - val_loss: 0.7776 - val_acc: 0.7742\n",
      "Epoch 9/20\n",
      "92056/92056 [==============================] - 367s 4ms/step - loss: 0.4729 - acc: 0.8467 - val_loss: 0.7777 - val_acc: 0.7811\n",
      "10221/10221 [==============================] - 16s 2ms/step\n",
      "102277/102277 [==============================] - 161s 2ms/step\n",
      "*******9*******\n",
      "Train on 92057 samples, validate on 10220 samples\n",
      "Epoch 1/20\n",
      "92057/92057 [==============================] - 366s 4ms/step - loss: 1.0407 - acc: 0.6982 - val_loss: 0.9709 - val_acc: 0.7193\n",
      "Epoch 2/20\n",
      "92057/92057 [==============================] - 365s 4ms/step - loss: 0.8317 - acc: 0.7528 - val_loss: 0.8357 - val_acc: 0.7537\n",
      "Epoch 3/20\n",
      "15808/92057 [====>.........................] - ETA: 4:50 - loss: 0.7439 - acc: 0.7765"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#logloss_list = []\n",
    "for i in range(10):\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    print('*******%s*******'%i)\n",
    "    idx_train = np.array(index[index['fold'] != i]['id'])\n",
    "    idx_val = np.array(index[index['fold'] == i]['id'])\n",
    "    \n",
    "    \n",
    "    X_train = train_FE.loc[idx_train, :]\n",
    "    y_train = categorical_labels[idx_train]\n",
    "\n",
    "    X_val = train_FE.loc[idx_val, :]\n",
    "    y_val = categorical_labels[idx_val]\n",
    "\n",
    "    #dtest = test.loc[:,user_col]\n",
    "    \n",
    "    X_train = get_input(X_train)\n",
    "    X_val = get_input(X_val)\n",
    "    X_test = get_input(test_FE)\n",
    "    \n",
    "    BATCH_SIZE = 64\n",
    "    bst_model_path = '10folds_' + 'base_rnn_wrod_v2_300dim' + str(i) + '.hdf5'\n",
    "    early_stopping =EarlyStopping(monitor='val_acc', patience=2)\n",
    "    model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
    "    callbacks = [\n",
    "            early_stopping,\n",
    "            model_checkpoint\n",
    "        ]\n",
    "    model = RNN1()\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',\\\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    hist = model.fit(X_train, y_train, \\\n",
    "            validation_data=(X_val, y_val), \\\n",
    "            epochs=20, batch_size=BATCH_SIZE, shuffle=True, callbacks=callbacks)#callbacks=callbacks\n",
    "    \n",
    "    model = RNN1()\n",
    "    model.load_weights(bst_model_path)\n",
    "    \n",
    "    pred = pd.DataFrame(model.predict(X_val,batch_size=64,verbose=1))\n",
    "    \n",
    "    for i in range(19):\n",
    "        meta_train.loc[idx_val, 'prob' + str(i)] = pred[i].values\n",
    "    \n",
    "    prob = model.predict(X_test,batch_size=64,verbose=1)\n",
    "    meta_test = pd.concat([meta_test, pd.DataFrame(prob)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******0*******\n",
      "Train on 92040 samples, validate on 10237 samples\n",
      "Epoch 1/20\n",
      "92040/92040 [==============================] - 661s 7ms/step - loss: 1.0202 - acc: 0.7068 - val_loss: 0.8836 - val_acc: 0.7358\n",
      "Epoch 2/20\n",
      "92040/92040 [==============================] - 661s 7ms/step - loss: 0.7874 - acc: 0.7650 - val_loss: 0.8301 - val_acc: 0.7525\n",
      "Epoch 3/20\n",
      "92040/92040 [==============================] - 661s 7ms/step - loss: 0.6982 - acc: 0.7883 - val_loss: 0.8085 - val_acc: 0.7693\n",
      "Epoch 4/20\n",
      "92040/92040 [==============================] - 659s 7ms/step - loss: 0.6064 - acc: 0.8143 - val_loss: 0.8040 - val_acc: 0.7654\n",
      "Epoch 5/20\n",
      "92040/92040 [==============================] - 659s 7ms/step - loss: 0.5027 - acc: 0.8404 - val_loss: 0.8374 - val_acc: 0.7667\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1271461,600] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_2/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_2/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_2/embeddings, embedding_2/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'embedding_2/embeddings/Assign', defined at:\n  File \"/home/libo/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/libo/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-90a20a7b429d>\", line 1, in <module>\n    get_ipython().run_cell_magic('time', '', \"#logloss_list = []\\nfor i in range(10):\\n    gc.collect()\\n    K.clear_session()\\n    print('*******%s*******'%i)\\n    idx_train = np.array(index[index['fold'] != i]['id'])\\n    idx_val = np.array(index[index['fold'] == i]['id'])\\n    \\n    \\n    X_train = train_FE.loc[idx_train, :]\\n    y_train = categorical_labels[idx_train]\\n\\n    X_val = train_FE.loc[idx_val, :]\\n    y_val = categorical_labels[idx_val]\\n\\n    #dtest = test.loc[:,user_col]\\n    \\n    X_train = get_input(X_train)\\n    X_val = get_input(X_val)\\n    X_test = get_input(test_FE)\\n    \\n    BATCH_SIZE = 64\\n    bst_model_path = '10folds_' + 'base_rnn_wrod_v1_600dim' + str(i) + '.hdf5'\\n    early_stopping =EarlyStopping(monitor='val_acc', patience=2)\\n    model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\\n    callbacks = [\\n            early_stopping,\\n            model_checkpoint\\n        ]\\n    model = RNN1()\\n    model.compile(optimizer='adam', loss='categorical_crossentropy',\\\\\\n                 metrics=['accuracy'])\\n    \\n\\n    hist = model.fit(X_train, y_train, \\\\\\n            validation_data=(X_val, y_val), \\\\\\n            epochs=20, batch_size=BATCH_SIZE, shuffle=True, callbacks=callbacks)#callbacks=callbacks\\n    \\n    model = RNN1()\\n    model.load_weights(bst_model_path)\\n    \\n    pred = pd.DataFrame(model.predict(X_val,batch_size=64,verbose=1))\\n    \\n    for i in range(19):\\n        meta_train.loc[idx_val, 'prob' + str(i)] = pred[i].values\\n    \\n    prob = model.predict(X_test,batch_size=64,verbose=1)\\n    meta_test = pd.concat([meta_test, pd.DataFrame(prob)], axis = 1)\")\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2103, in run_cell_magic\n    result = fn(magic_arg_s, cell)\n  File \"<decorator-gen-62>\", line 2, in time\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 1215, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 36, in <module>\n  File \"<ipython-input-12-e272b81b3171>\", line 18, in RNN1\n    char_embedding = api_embedding_layer(char_input)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 592, in __call__\n    self.build(input_shapes[0])\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 105, in build\n    dtype=self.dtype)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 416, in add_weight\n    constraint=constraint)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 396, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 366, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1271461,600] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_2/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_2/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_2/embeddings, embedding_2/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1271461,600] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_2/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_2/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_2/embeddings, embedding_2/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-e272b81b3171>\u001b[0m in \u001b[0;36mRNN1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                                return_sequences=True))\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mchar_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_embedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m#char_embedding = SpatialDropout1D(0.2)(char_embedding)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;31m# Load weights that were specified at layer instantiation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mparam_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2325\u001b[0m     \"\"\"\n\u001b[1;32m   2326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2328\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1271461,600] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_2/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_2/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_2/embeddings, embedding_2/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'embedding_2/embeddings/Assign', defined at:\n  File \"/home/libo/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/libo/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-90a20a7b429d>\", line 1, in <module>\n    get_ipython().run_cell_magic('time', '', \"#logloss_list = []\\nfor i in range(10):\\n    gc.collect()\\n    K.clear_session()\\n    print('*******%s*******'%i)\\n    idx_train = np.array(index[index['fold'] != i]['id'])\\n    idx_val = np.array(index[index['fold'] == i]['id'])\\n    \\n    \\n    X_train = train_FE.loc[idx_train, :]\\n    y_train = categorical_labels[idx_train]\\n\\n    X_val = train_FE.loc[idx_val, :]\\n    y_val = categorical_labels[idx_val]\\n\\n    #dtest = test.loc[:,user_col]\\n    \\n    X_train = get_input(X_train)\\n    X_val = get_input(X_val)\\n    X_test = get_input(test_FE)\\n    \\n    BATCH_SIZE = 64\\n    bst_model_path = '10folds_' + 'base_rnn_wrod_v1_600dim' + str(i) + '.hdf5'\\n    early_stopping =EarlyStopping(monitor='val_acc', patience=2)\\n    model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\\n    callbacks = [\\n            early_stopping,\\n            model_checkpoint\\n        ]\\n    model = RNN1()\\n    model.compile(optimizer='adam', loss='categorical_crossentropy',\\\\\\n                 metrics=['accuracy'])\\n    \\n\\n    hist = model.fit(X_train, y_train, \\\\\\n            validation_data=(X_val, y_val), \\\\\\n            epochs=20, batch_size=BATCH_SIZE, shuffle=True, callbacks=callbacks)#callbacks=callbacks\\n    \\n    model = RNN1()\\n    model.load_weights(bst_model_path)\\n    \\n    pred = pd.DataFrame(model.predict(X_val,batch_size=64,verbose=1))\\n    \\n    for i in range(19):\\n        meta_train.loc[idx_val, 'prob' + str(i)] = pred[i].values\\n    \\n    prob = model.predict(X_test,batch_size=64,verbose=1)\\n    meta_test = pd.concat([meta_test, pd.DataFrame(prob)], axis = 1)\")\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2103, in run_cell_magic\n    result = fn(magic_arg_s, cell)\n  File \"<decorator-gen-62>\", line 2, in time\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 1215, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 36, in <module>\n  File \"<ipython-input-12-e272b81b3171>\", line 18, in RNN1\n    char_embedding = api_embedding_layer(char_input)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 592, in __call__\n    self.build(input_shapes[0])\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 105, in build\n    dtype=self.dtype)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 416, in add_weight\n    constraint=constraint)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 396, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 366, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/libo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1271461,600] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_2/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_2/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_2/embeddings, embedding_2/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#logloss_list = []\n",
    "for i in range(10):\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    print('*******%s*******'%i)\n",
    "    idx_train = np.array(index[index['fold'] != i]['id'])\n",
    "    idx_val = np.array(index[index['fold'] == i]['id'])\n",
    "    \n",
    "    \n",
    "    X_train = train_FE.loc[idx_train, :]\n",
    "    y_train = categorical_labels[idx_train]\n",
    "\n",
    "    X_val = train_FE.loc[idx_val, :]\n",
    "    y_val = categorical_labels[idx_val]\n",
    "\n",
    "    #dtest = test.loc[:,user_col]\n",
    "    \n",
    "    X_train = get_input(X_train)\n",
    "    X_val = get_input(X_val)\n",
    "    X_test = get_input(test_FE)\n",
    "    \n",
    "    BATCH_SIZE = 64\n",
    "    bst_model_path = '10folds_' + 'base_rnn_wrod_v1_600dim' + str(i) + '.hdf5'\n",
    "    early_stopping =EarlyStopping(monitor='val_acc', patience=2)\n",
    "    model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
    "    callbacks = [\n",
    "            early_stopping,\n",
    "            model_checkpoint\n",
    "        ]\n",
    "    model = RNN1()\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',\\\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    hist = model.fit(X_train, y_train, \\\n",
    "            validation_data=(X_val, y_val), \\\n",
    "            epochs=20, batch_size=BATCH_SIZE, shuffle=True, callbacks=callbacks)#callbacks=callbacks\n",
    "    \n",
    "    model = RNN1()\n",
    "    model.load_weights(bst_model_path)\n",
    "    \n",
    "    pred = pd.DataFrame(model.predict(X_val,batch_size=64,verbose=1))\n",
    "    \n",
    "    for i in range(19):\n",
    "        meta_train.loc[idx_val, 'prob' + str(i)] = pred[i].values\n",
    "    \n",
    "    prob = model.predict(X_test,batch_size=64,verbose=1)\n",
    "    meta_test = pd.concat([meta_test, pd.DataFrame(prob)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102277, 19)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102277, 190)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_train.columns = ['meta_base_rnn_wrod_v2_300dim_' + x for x in meta_train.columns]\n",
    "\n",
    "p = pd.DataFrame()\n",
    "\n",
    "for i in range(19):\n",
    "    p[i] = meta_test[i].mean(axis = 1)\n",
    "\n",
    "p.columns = meta_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((102277, 19), (102277, 19))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape, meta_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_train.to_csv('/home/libo/daguan/stack_new/train_meta_base_rnn_word_v2_300dim.csv', index = None ,encoding = 'utf-8')\n",
    "\n",
    "p.to_csv('/home/libo/daguan/stack_new/test_meta_base_rnn_word_v2_300dim.csv', index = None ,encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_set.csv')\n",
    "\n",
    "pred = pd.DataFrame(test['id'])\n",
    "\n",
    "pred['class'] = np.argmax(p.values, axis=1) + 1\n",
    "\n",
    "pred.to_csv('/home/libo/daguan/stack_new/9.4.3.csv', index = None ,encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    \n",
    "    #Input layer\n",
    "    char_input = Input(shape=(max_sequence_length_api,), dtype='int32')\n",
    "    \n",
    "    api_embedding_layer = Embedding(nb_words,\n",
    "        embedding_dim,\n",
    "        weights=[api_embedding_matrix],\n",
    "        input_length=max_sequence_length_api,\n",
    "        trainable=False)\n",
    "    #char_embedding = api_embedding_layer(char_input)\n",
    "    with tf.device('/cpu:0'):\n",
    "        char_embedding = api_embedding_layer(char_input)\n",
    "\n",
    "    \n",
    "    char_rnn_1= Bidirectional(CuDNNLSTM(100, \n",
    "                                return_sequences=True))(char_embedding)\n",
    "    char_rnn_2= Bidirectional(CuDNNLSTM(100, \n",
    "                                return_sequences=True))(char_rnn_1)\n",
    "    \n",
    "#     char_rnn_1 = Lambda(lambda x:K.permute_dimensions(x, (0, 2, 1)))(char_rnn_1)\n",
    "#     char_rnn_2 = Lambda(lambda x:K.permute_dimensions(x, (0, 2, 1)))(char_rnn_2)\n",
    "\n",
    "    merged = concatenate([char_rnn_1, char_rnn_2], axis = 1)\n",
    "    \n",
    "    merged = GlobalAveragePooling1D()(merged)\n",
    "    #merged = Flatten()(merged)\n",
    "    #merged = Lambda(lambda x:K.permute_dimensions(x, (0, 2, 1)))(merged)\n",
    "    \n",
    "    merged = Dense(1024, activation='relu')(merged)\n",
    "\n",
    "    preds = Dense(19, activation = 'softmax')(merged)\n",
    "    \n",
    "    model = Model(inputs=[char_input],outputs=preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1000, 300)    381438300   input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 200)    321600      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 200)    241600      bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2000, 200)    0           bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 200)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         205824      global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 19)           19475       dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 382,226,799\n",
      "Trainable params: 788,499\n",
      "Non-trainable params: 381,438,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_train = pd.DataFrame(np.array([None]*train_FE.shape[0]*19).reshape(train_FE.shape[0], 19))\n",
    "meta_train.columns = ['prob' + str(x) for x in range(19)]\n",
    "meta_test = pd.DataFrame()\n",
    "\n",
    "label = train['class']\n",
    "\n",
    "label = label - 1\n",
    "\n",
    "categorical_labels = keras.utils.np_utils.to_categorical(label, num_classes=19)\n",
    "\n",
    "index = pd.read_csv('fold.csv')\n",
    "index['id'] = train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******0*******\n",
      "Train on 92040 samples, validate on 10237 samples\n",
      "Epoch 1/20\n",
      "92040/92040 [==============================] - 323s 4ms/step - loss: 1.1816 - acc: 0.6528 - val_loss: 0.9639 - val_acc: 0.7230\n",
      "Epoch 2/20\n",
      "92040/92040 [==============================] - 321s 3ms/step - loss: 0.8952 - acc: 0.7384 - val_loss: 0.8628 - val_acc: 0.7448\n",
      "Epoch 3/20\n",
      "92040/92040 [==============================] - 320s 3ms/step - loss: 0.8149 - acc: 0.7586 - val_loss: 0.8201 - val_acc: 0.7566\n",
      "Epoch 4/20\n",
      "92040/92040 [==============================] - 321s 3ms/step - loss: 0.7688 - acc: 0.7714 - val_loss: 0.8114 - val_acc: 0.7576\n",
      "Epoch 5/20\n",
      "92040/92040 [==============================] - 321s 3ms/step - loss: 0.7328 - acc: 0.7805 - val_loss: 0.7774 - val_acc: 0.7700\n",
      "Epoch 6/20\n",
      "92040/92040 [==============================] - 322s 4ms/step - loss: 0.7024 - acc: 0.7871 - val_loss: 0.7677 - val_acc: 0.7780\n",
      "Epoch 7/20\n",
      "92040/92040 [==============================] - 322s 4ms/step - loss: 0.6714 - acc: 0.7962 - val_loss: 0.7572 - val_acc: 0.7798\n",
      "Epoch 8/20\n",
      "92040/92040 [==============================] - 321s 3ms/step - loss: 0.6405 - acc: 0.8038 - val_loss: 0.7755 - val_acc: 0.7779\n",
      "Epoch 9/20\n",
      "92040/92040 [==============================] - 322s 3ms/step - loss: 0.6101 - acc: 0.8110 - val_loss: 0.7697 - val_acc: 0.7777\n",
      "10237/10237 [==============================] - 17s 2ms/step\n",
      "102277/102277 [==============================] - 173s 2ms/step\n",
      "*******1*******\n",
      "Train on 92043 samples, validate on 10234 samples\n",
      "Epoch 1/20\n",
      "92043/92043 [==============================] - 323s 4ms/step - loss: 1.1616 - acc: 0.6591 - val_loss: 0.9432 - val_acc: 0.7291\n",
      "Epoch 2/20\n",
      "92043/92043 [==============================] - 322s 3ms/step - loss: 0.8766 - acc: 0.7433 - val_loss: 0.8713 - val_acc: 0.7470\n",
      "Epoch 3/20\n",
      "92043/92043 [==============================] - 322s 4ms/step - loss: 0.8066 - acc: 0.7616 - val_loss: 0.8546 - val_acc: 0.7528\n",
      "Epoch 4/20\n",
      "92043/92043 [==============================] - 322s 3ms/step - loss: 0.7634 - acc: 0.7727 - val_loss: 0.8446 - val_acc: 0.7559\n",
      "Epoch 5/20\n",
      "92043/92043 [==============================] - 322s 3ms/step - loss: 0.7278 - acc: 0.7826 - val_loss: 0.8212 - val_acc: 0.7590\n",
      "Epoch 6/20\n",
      "92043/92043 [==============================] - 322s 3ms/step - loss: 0.6932 - acc: 0.7912 - val_loss: 0.7856 - val_acc: 0.7673\n",
      "Epoch 7/20\n",
      "92043/92043 [==============================] - 322s 4ms/step - loss: 0.6602 - acc: 0.8005 - val_loss: 0.7928 - val_acc: 0.7689\n",
      "Epoch 8/20\n",
      "92043/92043 [==============================] - 322s 3ms/step - loss: 0.6341 - acc: 0.8067 - val_loss: 0.7938 - val_acc: 0.7708\n",
      "Epoch 9/20\n",
      "92043/92043 [==============================] - 322s 3ms/step - loss: 0.6016 - acc: 0.8159 - val_loss: 0.8109 - val_acc: 0.7709\n",
      "Epoch 10/20\n",
      "92043/92043 [==============================] - 325s 4ms/step - loss: 0.5709 - acc: 0.8240 - val_loss: 0.8084 - val_acc: 0.7699\n",
      "Epoch 11/20\n",
      "92043/92043 [==============================] - 324s 4ms/step - loss: 0.5404 - acc: 0.8316 - val_loss: 0.8002 - val_acc: 0.7728\n",
      "Epoch 12/20\n",
      "92043/92043 [==============================] - 324s 4ms/step - loss: 0.5106 - acc: 0.8398 - val_loss: 0.8411 - val_acc: 0.7700\n",
      "Epoch 13/20\n",
      "92043/92043 [==============================] - 325s 4ms/step - loss: 0.4798 - acc: 0.8483 - val_loss: 0.8329 - val_acc: 0.7750\n",
      "Epoch 14/20\n",
      "92043/92043 [==============================] - 324s 4ms/step - loss: 0.4516 - acc: 0.8562 - val_loss: 0.8393 - val_acc: 0.7698\n",
      "Epoch 15/20\n",
      " 5760/92043 [>.............................] - ETA: 4:47 - loss: 0.4023 - acc: 0.8703"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#logloss_list = []\n",
    "for i in range(10):\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    print('*******%s*******'%i)\n",
    "    idx_train = np.array(index[index['fold'] != i]['id'])\n",
    "    idx_val = np.array(index[index['fold'] == i]['id'])\n",
    "    \n",
    "    \n",
    "    X_train = train_FE.loc[idx_train, :]\n",
    "    y_train = categorical_labels[idx_train]\n",
    "\n",
    "    X_val = train_FE.loc[idx_val, :]\n",
    "    y_val = categorical_labels[idx_val]\n",
    "\n",
    "    #dtest = test.loc[:,user_col]\n",
    "    \n",
    "    X_train = get_input(X_train)\n",
    "    X_val = get_input(X_val)\n",
    "    X_test = get_input(test_FE)\n",
    "    \n",
    "    BATCH_SIZE = 64\n",
    "    bst_model_path = '10folds_' + 'base_rnn_wrod_v2_300dim' + str(i) + '.hdf5'\n",
    "    early_stopping =EarlyStopping(monitor='val_acc', patience=2)\n",
    "    model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
    "    callbacks = [\n",
    "            early_stopping,\n",
    "            model_checkpoint\n",
    "        ]\n",
    "    model = RNN()\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',\\\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    hist = model.fit(X_train, y_train, \\\n",
    "            validation_data=(X_val, y_val), \\\n",
    "            epochs=20, batch_size=BATCH_SIZE, shuffle=True, callbacks=callbacks)#callbacks=callbacks\n",
    "    \n",
    "    model = RNN()\n",
    "    model.load_weights(bst_model_path)\n",
    "    \n",
    "    pred = pd.DataFrame(model.predict(X_val,batch_size=64,verbose=1))\n",
    "    \n",
    "    for i in range(19):\n",
    "        meta_train.loc[idx_val, 'prob' + str(i)] = pred[i].values\n",
    "    \n",
    "    prob = model.predict(X_test,batch_size=64,verbose=1)\n",
    "    meta_test = pd.concat([meta_test, pd.DataFrame(prob)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 300)    381438300   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 200)    321600      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 200)    241600      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2000, 200)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2000, 1024)   205824      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2000, 19)     19475       dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 382,226,799\n",
      "Trainable params: 788,499\n",
      "Non-trainable params: 381,438,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
